\chapter{Related Work}
% \section{foo}
First attempts to use a neural network for caries detection date back to 2008, when Kuang et al. \cite{Kuang2008} proposed an approach based on passing a patch from an image to a classifier, which decided if the patch contains caries or healthy enamel. Even though the performance of proposed neural network was surpassed by 6.72\% by kernel SVM, it was still able to outperform an ordinary dentist by more than 5\% and was only 6\% worse than an experienced one. Since 2015, when second attempt to solve caries detection using neural networks took place, there has been a growing amount of studies in this area. More than 10 of them have been published since 2017 \cite{PradosPrivado2020}. The difference between them is in the type of image used to detect caries. Following types of images have been used: Near-Infrared Transillumination images \cite{Casalegno2019,Schwendicke2020}, camera photographs \cite{Moutselos2019} and X-ray images, which may be further divided into bitewing X-ray images \cite{Moran2021, Cantu2020, Bayrakdar2021, Mao2021, Srivastava2017} panoramatic X-ray images \cite{Lian2021} and periapical X-ray images \cite{Lee2018}.
There are three main different categories of caries detection:
\begin{itemize}
    \item Classification, where the goal is to classify the given patch as containing one ore more caries having a predefined patch.
    \item Pixel-wise segmentation, where for each pixel it is decided if it is part of caries lesion or otherwise.
    \item Detection, where we need to draw a tight box around each tooth decay.
\end{itemize}
\subsection{Approaches in Related publications}
A very popular paper in this field of study was published in 2018 \cite{Lee2018}. The approach was as follows: Periapical X-ray images were manually divided into patches containing a single centered tooth. This image was resized to 299x299 pixels and passed thru GogLeNet Inception v3 convolutional neural network (CNN). The output of this network was a binary classification dental caries or non-dental caries. The study had 3000 tooth images available at their disposal.

Srivasta et al. \cite{Srivastava2017} approached this task as object detection. They used 3000 images with cavity-wise annotations to train a fully convolutional neural network with more than 100 layers. It is a pity they did not include more details about the architecture used. Since, according to their results, they were able to achieve a recall almost two times better(33\% to 46\% better recall) than 3 dentists involved in the experiment while maintaining only 2\% to 20\% worse precision. \\

Another eyebrows-raising publication is proposed by \cite{Bayrakdar2021}, where they claim to achieve 84\% detection precision while using VGGNet. This is suspicious since VGGNet is an architecture used for classification, and they did not mention any detection head they had supposedly used, nor other modifications they had done to make this architecture be able to detect objects. They neither explain the reasoning behind choosing a 7-year-old architecture. They could extract patches containing teeth from images and use them for classification, but there was no information provided on this subject, nor did they mention word classification.

The same author (and his colleague) published another study \cite{Bayraktar2021} where they learned YOLO V3 network on 1000 bitewing images, resulting in 94.59\% accuracy and 72.26\% sensitivity. Threshold to count detection as correct was intersection over union (IOU) greater than 0.5. Here, we can find here a few suspicious things as well. Why did the author choose YOLO V3  \cite{Redmon2018} architecture? This architecture excels at low latency detection, which is usually not requested when detecting dental caries, and at the time of the publication, there was a newer version of YOLO already available surpassing YOLO V3 by 12\% \cite{Bochovskiy2020}. The author mentions that the network was trained for 5000 epochs. This is highly unusual and should cause things such as over-fitting, especially when the training set contained 800 images only. We mention this, because reader should take those things in consideration when comparing results presented in mentioned papers with the results of our own.

There are two publications \cite{Mao2021, Moran2021}, where an approach based on detecting teeth by non-deep learning methods, such as binarization, projection, and morphology operation, was proposed. After the detection of a tooth, a patch from the image is extracted and passed to a classificational neural network. In mentioned publications, they used Inception and ResNet architectures.