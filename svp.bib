@Article{Moran2021,
  author    = {Maira Moran and Marcelo Faria and Gilson Giraldi and Luciana Bastos and Larissa Oliveira and Aura Conci},
  journal   = {Sensors},
  title     = {Classification of Approximal Caries in Bitewing Radiographs Using Convolutional Neural Networks},
  year      = {2021},
  month     = {jul},
  number    = {15},
  pages     = {5192},
  volume    = {21},
  comment   = {Non DL preprocess, classfication Inception, ResNet, 480 bitewing imgs},
  doi       = {10.3390/s21155192},
  file      = {:/home/kuntik/Documents/svp/papers/MoranClassification.pdf:PDF},
  groups    = {Dental},
  publisher = {{MDPI} {AG}},
}

@Article{Lian2021,
  author    = {Luya Lian and Tianer Zhu and Fudong Zhu and Haihua Zhu},
  journal   = {Diagnostics},
  title     = {Deep Learning for Caries Detection and Classification},
  year      = {2021},
  month     = {sep},
  number    = {9},
  pages     = {1672},
  volume    = {11},
  comment   = {U-net seg plus classification by severity, 1160 panoramic images},
  doi       = {10.3390/diagnostics11091672},
  file      = {:/home/kuntik/Documents/svp/papers/LianUnetsegClass.pdf:PDF},
  groups    = {Dental},
  publisher = {{MDPI} {AG}},
}

@Article{Cantu2020,
  author     = {Anselmo Garcia Cantu and Sascha Gehrung and Joachim Krois and Akhilanand Chaurasia and Jesus Gomez Rossi and Robert Gaudin and Karim Elhennawy and Falk Schwendicke},
  journal    = {Journal of Dentistry},
  title      = {Detecting caries lesions of different radiographic extension on bitewings using deep learning},
  year       = {2020},
  month      = {sep},
  pages      = {103425},
  volume     = {100},
  comment    = {U-net segmentation 3686 bitewing},
  doi        = {10.1016/j.jdent.2020.103425},
  file       = {:/home/kuntik/Documents/svp/papers/CantuUnetSegBitewing.pdf:PDF},
  groups     = {Dental},
  publisher  = {Elsevier {BV}},
  readstatus = {skimmed},
}

@Article{Lee2018,
  author    = {Jae-Hong Lee and Do-Hyung Kim and Seong-Nyum Jeong and Seong-Ho Choi},
  journal   = {Journal of Dentistry},
  title     = {Detection and diagnosis of dental caries using a deep learning-based convolutional neural network algorithm},
  year      = {2018},
  month     = {oct},
  pages     = {106--111},
  volume    = {77},
  comment   = {Manual detection, InceptionNet classification, 3000k periapical images},
  doi       = {10.1016/j.jdent.2018.07.015},
  file      = {:/home/kuntik/Documents/svp/papers/LeeManualDetClass.pdf:PDF},
  groups    = {Dental},
  publisher = {Elsevier {BV}},
}

@Article{Srivastava2017,
  author        = {Muktabh Mayank Srivastava and Pratyush Kumar and Lalit Pradhan and Srikrishna Varadarajan},
  journal       = {CoRR},
  title         = {Detection of Tooth caries in Bitewing Radiographs using Deep Learning},
  year          = {2017},
  volume        = {abs/1711.07312},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1711-07312.bib},
  comment       = {Detection FCNN(Unspecified) architecture, 3000imgs bitewing},
  eprint        = {1711.07312},
  file          = {:/home/kuntik/Documents/svp/papers/Srivastava3000k.pdf:PDF},
  groups        = {Dental},
  timestamp     = {Mon, 13 Aug 2018 16:47:35 +0200},
  url           = {http://arxiv.org/abs/1711.07312},
}

@Article{Mao2021,
  author  = {Yi-Cheng Mao and Tsung-Yi Chen and He-Sheng Chou and Szu-Yin Lin and Sheng-Yu Liu and Yu-An Chen and Yu-Lin Liu and Chiung-An Chen and Yen-Cheng Huang and Shih-Lun Chen and Chun-Wei Li and Patricia Angela R. Abu and W Y Chiang},
  journal = {Sensors (Basel, Switzerland)},
  title   = {Caries and Restoration Detection Using Bitewing Film Based on Transfer Learning with CNNs},
  year    = {2021},
  volume  = {21},
  comment = {Non dl preprocessing, classification AlexNet, ResNet, VggNet 278 bitewing im},
  file    = {:/home/kuntik/Documents/svp/papers/MaoBitewingClassification.pdf:PDF},
  groups  = {Dental},
}

@InProceedings{Moutselos2019,
  author    = {K. Moutselos and E. Berdouses and C. Oulis and I. Maglogiannis},
  booktitle = {2019 41st Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
  title     = {Recognizing Occlusal Caries in Dental Intraoral Images Using Deep Learning},
  year      = {2019},
  month     = {jul},
  publisher = {{IEEE}},
  comment   = {Dental caries, normal images, segmentation ResNet},
  doi       = {10.1109/embc.2019.8856553},
  groups    = {Dental},
}

@Article{Bayrakdar2021,
  author    = {Ibrahim Sevki Bayrakdar and Kaan Orhan and Serdar Akarsu and Özer {\c{C}}elik and Samet Atasoy and Adem Pekince and Yasin Yasa and Elif Bilgir and Hande Sa{\u{g}}lam and Ahmet Faruk Aslan and Alper Odaba{\c{s}}},
  journal   = {Oral Radiology},
  title     = {Deep-learning approach for caries detection and segmentation on dental bitewing radiographs},
  year      = {2021},
  month     = {nov},
  comment   = {sketchy detection and segmentation. VGG used? 621 bitewing},
  doi       = {10.1007/s11282-021-00577-9},
  file      = {:/home/kuntik/Documents/svp/papers/Bayrakdar2021_Article_Deep-learningApproachForCaries.pdf:PDF},
  groups    = {Dental},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Yasa2020,
  author    = {Yasin Yasa and Özer {\c{C}}elik and Ibrahim Sevki Bayrakdar and Adem Pekince and Kaan Orhan and Serdar Akarsu and Samet Atasoy and Elif Bilgir and Alper Odaba{\c{s}} and Ahmet Faruk Aslan},
  journal   = {Acta Odontologica Scandinavica},
  title     = {An artificial intelligence proposal to automatic teeth detection and numbering in dental bite-wing radiographs},
  year      = {2020},
  month     = {nov},
  number    = {4},
  pages     = {275--281},
  volume    = {79},
  comment   = {R-CNN used for detection - accuracy too high},
  doi       = {10.1080/00016357.2020.1840624},
  groups    = {Dental},
  publisher = {Informa {UK} Limited},
}

@Article{Bayraktar2021,
  author    = {Yusuf Bayraktar and Enes Ayan},
  journal   = {Clinical Oral Investigations},
  title     = {Diagnosis of interproximal caries lesions with deep convolutional neural network in digital bitewing radiographs},
  year      = {2021},
  month     = {jun},
  comment   = {YOLO v3 bitweing caries detection},
  doi       = {10.1007/s00784-021-04040-1},
  file      = {:/home/kuntik/Documents/svp/papers/Bayraktar_yolo3.pdf:PDF},
  groups    = {Dental},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Tan2019,
  author        = {Mingxing Tan and Ruoming Pang and Quoc V. Le},
  journal       = {CoRR},
  title         = {EfficientDet: Scalable and Efficient Object Detection},
  year          = {2019},
  volume        = {abs/1911.09070},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1911-09070.bib},
  comment       = {EfficientDet},
  eprint        = {1911.09070},
  file          = {:/home/kuntik/Documents/svp/papers/EfficientDet.pdf:PDF},
  groups        = {architectures},
  timestamp     = {Tue, 03 Dec 2019 14:15:54 +0100},
  url           = {http://arxiv.org/abs/1911.09070},
}

@Article{Tan2019a,
  author        = {Mingxing Tan and Quoc V. Le},
  journal       = {CoRR},
  title         = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  year          = {2019},
  volume        = {abs/1905.11946},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1905-11946.bib},
  comment       = {EfficientNet},
  eprint        = {1905.11946},
  file          = {:/home/kuntik/Documents/svp/papers/EfficientNet.pdf:PDF},
  groups        = {architectures},
  timestamp     = {Mon, 03 Jun 2019 13:42:33 +0200},
  url           = {http://arxiv.org/abs/1905.11946},
}

@Article{Redmon2018,
  author        = {Joseph Redmon and Ali Farhadi},
  journal       = {CoRR},
  title         = {YOLOv3: An Incremental Improvement},
  year          = {2018},
  volume        = {abs/1804.02767},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1804-02767.bib},
  comment       = {YoloV3},
  eprint        = {1804.02767},
  file          = {:/home/kuntik/Documents/svp/papers/YOLOV3.pdf:PDF},
  groups        = {architectures},
  timestamp     = {Mon, 13 Aug 2018 16:48:24 +0200},
  url           = {http://arxiv.org/abs/1804.02767},
}

@Article{Redmon2015,
  author        = {Joseph Redmon and Santosh Kumar Divvala and Ross B. Girshick and Ali Farhadi},
  journal       = {CoRR},
  title         = {You Only Look Once: Unified, Real-Time Object Detection},
  year          = {2015},
  volume        = {abs/1506.02640},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/RedmonDGF15.bib},
  comment       = {Yolo},
  eprint        = {1506.02640},
  file          = {:/home/kuntik/Documents/svp/papers/YOLO.pdf:PDF},
  groups        = {architectures},
  timestamp     = {Mon, 13 Aug 2018 16:48:08 +0200},
  url           = {http://arxiv.org/abs/1506.02640},
}

@Article{Ren2015,
  author        = {Shaoqing Ren and Kaiming He and Ross B. Girshick and Jian Sun},
  journal       = {CoRR},
  title         = {Faster {R-CNN:} Towards Real-Time Object Detection with Region Proposal Networks},
  year          = {2015},
  volume        = {abs/1506.01497},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/RenHG015.bib},
  comment       = {Faster R-CNN},
  eprint        = {1506.01497},
  file          = {:papers/Faster R-CNN.pdf:PDF},
  groups        = {architectures},
  timestamp     = {Mon, 13 Aug 2018 16:46:02 +0200},
  url           = {http://arxiv.org/abs/1506.01497},
}

@Article{Girshick2013,
  author        = {Ross B. Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},
  journal       = {CoRR},
  title         = {Rich feature hierarchies for accurate object detection and semantic segmentation},
  year          = {2013},
  volume        = {abs/1311.2524},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/GirshickDDM13.bib},
  comment       = {RCNN},
  eprint        = {1311.2524},
  file          = {:papers/RCNN.pdf:PDF},
  groups        = {architectures},
  timestamp     = {Mon, 13 Aug 2018 16:48:09 +0200},
  url           = {http://arxiv.org/abs/1311.2524},
}

@Article{James2018,
  author    = {James, Spencer L. Abate, Degu et al.},
  journal   = {The Lancet},
  title     = {Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990{\textendash}2017: a systematic analysis for the Global Burden of Disease Study 2017},
  year      = {2018},
  month     = {nov},
  number    = {10159},
  pages     = {1789--1858},
  volume    = {392},
  comment   = {Diseases summary},
  doi       = {10.1016/s0140-6736(18)32279-7},
  file      = {:papers/1-s2.0-S0140673618322797-main.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Bhatt2020,
  author    = {Chandradeep Bhatt and Indrajeet Kumar and V. Vijayakumar and Kamred Udham Singh and Abhishek Kumar},
  journal   = {Multimedia Systems},
  title     = {The state of the art of deep learning models in medical science and their challenges},
  year      = {2020},
  month     = {sep},
  number    = {4},
  pages     = {599--613},
  volume    = {27},
  comment   = {Number of articles in medical field in recent},
  doi       = {10.1007/s00530-020-00694-1},
  file      = {:papers/Bhatt2021_Article_TheStateOfTheArtOfDeepLearning.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{PradosPrivado2020,
  author    = {Mar{\'{\i}}a Prados-Privado and Javier Garc{\'{\i}}a Villal{\'{o}}n and Carlos Hugo Mart{\'{\i}}nez-Mart{\'{\i}}nez and Carlos Ivorra and Juan Carlos Prados-Frutos},
  journal   = {Journal of Clinical Medicine},
  title     = {Dental Caries Diagnosis and Detection Using Neural Networks: A Systematic Review},
  year      = {2020},
  month     = {nov},
  number    = {11},
  pages     = {3579},
  volume    = {9},
  comment   = {Review of methods in dental caries detection (using NN)},
  doi       = {10.3390/jcm9113579},
  file      = {:papers/jcm-09-03579 (1).pdf:PDF},
  publisher = {{MDPI} {AG}},
}

@InProceedings{Kuang2008,
  author    = {Wei Kuang and Weiping Ye},
  booktitle = {2008 Second International Symposium on Intelligent Information Technology Application},
  title     = {A Kernel-Modified {SVM} Based Computer-Aided Diagnosis System in Initial Caries},
  year      = {2008},
  month     = {dec},
  publisher = {{IEEE}},
  comment   = {2008 SVM and NN for caries classification},
  doi       = {10.1109/iita.2008.206},
  file      = {:papers/A_Kernel-Modified_SVM_Based_Computer-Aided_Diagnosis_System_in_Initial_Caries.pdf:PDF},
}

@Article{Schwendicke2020,
  author    = {Falk Schwendicke and Karim Elhennawy and Sebastian Paris and Philipp Friebertshäuser and Joachim Krois},
  journal   = {Journal of Dentistry},
  title     = {Deep learning for caries lesion detection in near-infrared light transillumination images: A pilot study},
  year      = {2020},
  month     = {jan},
  pages     = {103260},
  volume    = {92},
  comment   = {Near IR images detection},
  doi       = {10.1016/j.jdent.2019.103260},
  publisher = {Elsevier {BV}},
}

@Article{Casalegno2019,
  author    = {F. Casalegno and T. Newton and R. Daher and M. Abdelaziz and A. Lodi-Rizzini and F. Schürmann and I. Krejci and H. Markram},
  journal   = {Journal of Dental Research},
  title     = {Caries Detection with Near-Infrared Transillumination Using Deep Learning},
  year      = {2019},
  month     = {aug},
  number    = {11},
  pages     = {1227--1233},
  volume    = {98},
  comment   = {Near IR images detection},
  doi       = {10.1177/0022034519871884},
  publisher = {{SAGE} Publications},
}

@Article{Bochkovskiy2020,
  author        = {Alexey Bochkovskiy and Chien{-}Yao Wang and Hong{-}Yuan Mark Liao},
  journal       = {CoRR},
  title         = {YOLOv4: Optimal Speed and Accuracy of Object Detection},
  year          = {2020},
  volume        = {abs/2004.10934},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2004-10934.bib},
  comment       = {YoloV4},
  eprint        = {2004.10934},
  groups        = {architectures},
  timestamp     = {Tue, 28 Apr 2020 16:10:02 +0200},
  url           = {https://arxiv.org/abs/2004.10934},
}

@Misc{MetaAIStatement,
  title    = {Reengineering {Facebook} {AI}’s deep learning platforms for interoperability},
  abstract = {Having a single set of interchangeable building blocks across different AI subfields will help accelerate progress. We’re reengineering our platforms, using Hydra for configs, and offering greater integration with PyTorch Lightning.},
  comment  = {MetaAI statement obout PL and Hydra},
  language = {cs},
  url      = {https://ai.facebook.com/blog/reengineering-facebook-ais-deep-learning-platforms-for-interoperability/},
  urldate  = {2022-01-14},
}

@Article{falcon2019pytorch,
  author  = {William {Falcon et al.}},
  journal = {GitHub. Note: https://github.com/PyTorchLightning/pytorch-lightning},
  title   = {PyTorch Lightning},
  year    = {2019},
  volume  = {3},
  comment = {Pytorch-Lightning Library},
}

@Misc{paperwithcode,
  title    = {Papers with {Code} - {Browse} the {State}-of-the-{Art} in {Machine} {Learning}},
  abstract = {6032 leaderboards • 2611 tasks • 5394 datasets • 63142 papers with code.},
  comment  = {state of the art leaderboard},
  language = {en},
  url      = {https://paperswithcode.com/sota},
  urldate  = {2022-01-14},
}

@Misc{Yadan2019Hydra,
  author       = {Omry Yadan},
  howpublished = {Github},
  title        = {Hydra - A framework for elegantly configuring complex applications},
  year         = {2019},
  comment      = {Hydra},
  url          = {https://github.com/facebookresearch/hydra},
}

@Misc{cavityarticle,
  title    = {Cavities/tooth decay - {Symptoms} and causes},
  abstract = {Cavities, also called tooth decay, are permanently damaged areas in the hard surface of your teeth that develop into tiny openings or holes.},
  comment  = {Cavity article},
  journal  = {Mayo Clinic},
  language = {en},
  url      = {https://www.mayoclinic.org/diseases-conditions/cavities/symptoms-causes/syc-20352892},
  urldate  = {2022-01-14},
}

@Software{glennjocher2020,
  author    = {Glenn Jocher et al.},
  comment   = {YoloV5},
  doi       = {10.5281/zenodo.4154370},
  groups    = {architectures},
  month     = oct,
  publisher = {Zenodo},
  title     = {{ultralytics/yolov5: v3.1 - Bug Fixes and Performance Improvements}},
  url       = {https://doi.org/10.5281/zenodo.4154370},
  version   = {v3.1},
  year      = {2020},
}

@Article{Everingham2009,
  author         = {Mark Everingham and Luc Van Gool and Christopher K. I. Williams and John Winn and Andrew Zisserman},
  journal        = {International Journal of Computer Vision},
  title          = {The Pascal Visual Object Classes ({VOC}) Challenge},
  year           = {2009},
  month          = {sep},
  number         = {2},
  pages          = {303--338},
  volume         = {88},
  comment        = {Pascal voc dataset paper},
  doi            = {10.1007/s11263-009-0275-4},
  file           = {:/home/kuntik/Documents/svp/papers/PascalVOC.pdf:PDF},
  publisher      = {Springer Science and Business Media {LLC}},
  qualityassured = {qualityAssured},
}

@Article{Padilla2021,
  author    = {Rafael Padilla and Wesley L. Passos and Thadeu L. B. Dias and Sergio L. Netto and Eduardo A. B. da Silva},
  journal   = {Electronics},
  title     = {A Comparative Analysis of Object Detection Metrics with a Companion Open-Source Toolkit},
  year      = {2021},
  month     = {jan},
  number    = {3},
  pages     = {279},
  volume    = {10},
  comment   = {Object detection metrics overview},
  doi       = {10.3390/electronics10030279},
  file      = {:/home/kuntik/Documents/svp/papers/metrics.pdf:PDF},
  publisher = {{MDPI} {AG}},
}

@Article{Cowton2019,
  author    = {Jake Cowton and Ilias Kyriazakis and Jaume Bacardit},
  journal   = {{IEEE} Access},
  title     = {Automated Individual Pig Localisation, Tracking and Behaviour Metric Extraction Using Deep Learning},
  year      = {2019},
  pages     = {108049--108060},
  volume    = {7},
  comment   = {IOU image},
  doi       = {10.1109/access.2019.2933060},
  groups    = {images},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  ranking   = {rank1},
}

@InProceedings{Padilla2020,
  author    = {Rafael Padilla and Sergio L. Netto and Eduardo A. B. da Silva},
  booktitle = {2020 International Conference on Systems, Signals and Image Processing ({IWSSIP})},
  title     = {A Survey on Performance Metrics for Object-Detection Algorithms},
  year      = {2020},
  month     = {jul},
  publisher = {{IEEE}},
  comment   = {Object detection metrics survey},
  doi       = {10.1109/iwssip48289.2020.9145130},
  file      = {:/home/kuntik/Documents/svp/papers/Metrics_survey.pdf:PDF},
}

@Misc{Cubuk2018,
  author    = {Cubuk, Ekin D. and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V.},
  title     = {AutoAugment: Learning Augmentation Policies from Data},
  year      = {2018},
  comment   = {auto augment},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1805.09501},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Book{2019a,
  publisher = {Elsevier},
  title     = {Sturdevant{\textquotesingle}s Art and Science of Operative Dentistry},
  year      = {2019},
  comment   = {Book about dentistry, from MDDR Tichy},
  doi       = {10.1016/c2015-0-05603-9},
  groups    = {Dental},
}

@Article{Frencken2017,
  author    = {Jo E. Frencken and Praveen Sharma and Laura Stenhouse and David Green and Dominic Laverty and Thomas Dietrich},
  journal   = {Journal of Clinical Periodontology},
  title     = {Global epidemiology of dental caries and severe periodontitis - a comprehensive review},
  year      = {2017},
  month     = {mar},
  pages     = {S94--S105},
  volume    = {44},
  comment   = {Epidemiology of dental caries},
  doi       = {10.1111/jcpe.12677},
  groups    = {Dental},
  publisher = {Wiley},
}

@Article{Kassebaum2015,
  author    = {Kassebaum, N. J. and Bernabé, E. and Dahiya, M. and Bhandari, B. and Murray, C. J. L. and Marcenes, W.},
  journal   = {J Dent Res},
  title     = {Global Burden of Untreated Caries: A Systematic Review and Metaregression},
  year      = {2015},
  issn      = {0022-0345},
  month     = mar,
  number    = {5},
  pages     = {650--658},
  volume    = {94},
  abstract  = {We aimed to consolidate all epidemiologic data about untreated caries and subsequently generate internally consistent prevalence and incidence estimates for all countries, 20 age groups, and both sexes for 1990 and 2010. The systematic search of the literature yielded 18,311 unique citations. After screening titles and abstracts, we excluded 10,461 citations as clearly irrelevant to this systematic review, leaving 1,682 for full-text review. Furthermore, 1,373 publications were excluded following the validity assessment. Overall, 192 studies of 1,502,260 children aged 1 to 14 y in 74 countries and 186 studies of 3,265,546 individuals aged 5 y or older in 67 countries were included in separate metaregressions for untreated caries in deciduous and permanent teeth, respectively, using modeling resources from the Global Burden of Disease 2010 study. In 2010, untreated caries in permanent teeth was the most prevalent condition worldwide, affecting 2.4 billion people, and untreated caries in deciduous teeth was the 10th-most prevalent condition, affecting 621 million children worldwide. The global age-standardized prevalence and incidence of untreated caries remained static between 1990 and 2010. There is evidence that the burden of untreated caries is shifting from children to adults, with 3 peaks in prevalence at ages 6, 25, and 70 y. Also, there were considerable variations in prevalence and incidence between regions and countries. Policy makers need to be aware of a predictable increasing burden of untreated caries due to population growth and longevity and a significant decrease in the prevalence of total tooth loss throughout the world from 1990 to 2010.},
  comment   = {Epidemiology total numbers},
  doi       = {10.1177/0022034515573272},
  groups    = {Dental},
  publisher = {SAGE Publications Inc},
  url       = {https://doi.org/10.1177/0022034515573272},
}

@Article{Hung2020,
  author    = {Man Hung and Martin S. Lipsky and Ryan Moffat and Evelyn Lauren and Eric S. Hon and Jungweon Park and Gagandeep Gill and Julie Xu and Lourdes Peralta and Joseph Cheever and David Prince and Tanner Barton and Nicole Bayliss and Weston Boyack and Frank W. Licari},
  journal   = {{PLOS} {ONE}},
  title     = {Health and dental care expenditures in the United States from 1996 to 2016},
  year      = {2020},
  month     = {jun},
  number    = {6},
  pages     = {e0234459},
  volume    = {15},
  comment   = {USA spending dental health care},
  doi       = {10.1371/journal.pone.0234459},
  editor    = {Fr{\'{e}}d{\'{e}}ric Denis},
  groups    = {Dental},
  publisher = {Public Library of Science ({PLoS})},
}

@Article{Rosenblatt1958,
  author    = {F. Rosenblatt},
  journal   = {Psychological Review},
  title     = {The perceptron: A probabilistic model for information storage and organization in the brain.},
  year      = {1958},
  number    = {6},
  pages     = {386--408},
  volume    = {65},
  comment   = {perceptron},
  doi       = {10.1037/h0042519},
  publisher = {American Psychological Association ({APA})},
}

@Misc{Du2020,
  author   = {Du, Shuchen},
  month    = may,
  title    = {Understanding {Deep} {Self}-attention {Mechanism} in {Convolution} {Neural} {Networks}},
  year     = {2020},
  abstract = {Limitations and improvements of encoder-decoder architectures},
  comment  = {Conv image},
  groups   = {images},
  language = {en},
  url      = {https://medium.com/ai-salon/understanding-deep-self-attention-mechanism-in-convolution-neural-networks-e8f9c01cb251},
  urldate  = {2022-05-04},
}

@Book{Zhang2018,
  author  = {Zhang, Guoqiang and Li, H.},
  title   = {Effectiveness of Scaled Exponentially-Regularized Linear Units (SERLUs)},
  year    = {2018},
  month   = jul,
  comment = {Relu graphs},
  groups  = {images},
}

@Misc{Ioffe2015,
  author    = {Ioffe, Sergey and Szegedy, Christian},
  month     = jun,
  title     = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  year      = {2015},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
  comment   = {Batch normalisation},
  editor    = {Bach, Francis and Blei, David},
  file      = {:/home/kuntik/Documents/svp/papers/batch_norm.pdf:PDF},
  pages     = {448--456},
  publisher = {PMLR},
  refid     = {pmlr-v37-ioffe15},
  url       = {https://proceedings.mlr.press/v37/ioffe15.html},
  volume    = {37},
}

@Misc{Chen2019,
  author    = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},
  title     = {MMDetection: Open MMLab Detection Toolbox and Benchmark},
  year      = {2019},
  comment   = {mmdet paper},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1906.07155},
  groups    = {images},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Image and Video Processing (eess.IV), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering},
  publisher = {arXiv},
}

@Misc{He2015,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title     = {Deep Residual Learning for Image Recognition},
  year      = {2015},
  comment   = {ResNet},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1512.03385},
  file      = {:/home/kuntik/Documents/svp/papers/resnet.pdf:PDF},
  groups    = {architectures},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{Li2017,
  author    = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  title     = {Visualizing the Loss Landscape of Neural Nets},
  year      = {2017},
  comment   = {ResNet loss},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1712.09913},
  groups    = {images},
  keywords  = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{Dosovitskiy2020,
  author    = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  year      = {2020},
  comment   = {Vision transformer},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2010.11929},
  file      = {:/home/kuntik/Documents/svp/papers/VisionTransformer.pdf:PDF},
  groups    = {architectures, images},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  publisher = {arXiv},
}

@InProceedings{Namuk2022,
  author    = {Namuk Park and Songkuk Kim},
  booktitle = {International Conference on Learning Representations},
  title     = {How Do Vision Transformers Work?},
  year      = {2022},
  comment   = {Differences between convnets and transformers},
  file      = {:/home/kuntik/Documents/svp/papers/HowVisionTransformersWork.pdf:PDF},
  groups    = {architectures},
  url       = {https://openreview.net/forum?id=D78Go4hVcxO},
}

@Book{Yin2020,
  author  = {Yin, Kayo},
  title   = {Sign Language Translation with Transformers},
  year    = {2020},
  month   = apr,
  comment = {Transformer image},
  groups  = {images},
}

@InCollection{Li2018,
  author    = {Li, Yang and Yang, Tao},
  booktitle = {Guide to Big Data Applications},
  publisher = {Springer International Publishing},
  title     = {Word Embedding for Understanding Natural Language: A Survey},
  year      = {2018},
  address   = {Cham},
  editor    = {Srinivasan, S.},
  pages     = {83--104},
  abstract  = {Word embedding, where semantic and syntactic features are captured from unlabeled text data, is a basic procedure in Natural Language Processing (NLP). The extracted features thus could be organized in low dimensional space. Some representative word embedding approaches include Probability Language Model, Neural Networks Language Model, Sparse Coding, etc. The state-of-the-art methods like skip-gram negative samplings, noise-contrastive estimation, matrix factorization and hierarchical structure regularizer are applied correspondingly to resolve those models. Most of these literatures are working on the observed count and co-occurrence statistic to learn the word embedding. The increasing scale of data, the sparsity of data representation, word position, and training speed are the main challenges for designing word embedding algorithms. In this survey, we first introduce the motivation and background of word embedding. Next we will introduce the methods of text representation as preliminaries, as well as some existing word embedding approaches such as Neural Network Language Model and Sparse Coding Approach, along with their evaluation metrics. In the end, we summarize the applications of word embedding and discuss its future directions.},
  comment   = {Word embedings for NLP},
  doi       = {10.1007/978-3-319-53817-4_4},
  issn      = {978-3-319-53817-4},
  refid     = {Li2018},
  url       = {https://doi.org/10.1007/978-3-319-53817-4_4},
}

@InProceedings{Liu2021,
  author    = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  title     = {Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows},
  year      = {2021},
  month     = {October},
  pages     = {10012-10022},
  comment   = {Swin transformer},
  file      = {:/home/kuntik/Documents/svp/papers/SwinTransformer.pdf:PDF},
  groups    = {architectures},
}

@InProceedings{He2015ICCV,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
  year      = {2015},
  month     = {December},
  comment   = {Surpassing human-level performance ImageNet},
}

@Article{Aggarwal2021,
  author  = {Aggarwal, Ravi and Sounderajah, Viknesh and Martin, Guy and Ting, Daniel S. W. and Karthikesalingam, Alan and King, Dominic and Ashrafian, Hutan and Darzi, Ara},
  journal = {npj Digital Medicine},
  title   = {Diagnostic accuracy of deep learning in medical imaging: a systematic review and meta-analysis},
  year    = {2021},
  issn    = {2398-6352},
  number  = {1},
  pages   = {65},
  volume  = {4},
  comment = {Deep learning in medical imaging survey 2020},
  doi     = {10.1038/s41746-021-00438-z},
  refid   = {Aggarwal2021},
  url     = {https://doi.org/10.1038/s41746-021-00438-z},
}

@Article{RodriguezRuiz2019,
  author    = {Alejandro Rodriguez-Ruiz and Kristina L{\aa}ng and Albert Gubern-Merida and Mireille Broeders and Gisella Gennaro and Paola Clauser and Thomas H Helbich and Margarita Chevalier and Tao Tan and Thomas Mertelmeier and Matthew G Wallis and Ingvar Andersson and Sophia Zackrisson and Ritse M Mann and Ioannis Sechopoulos},
  journal   = {{JNCI}: Journal of the National Cancer Institute},
  title     = {Stand-Alone Artificial Intelligence for Breast Cancer Detection in Mammography: Comparison With 101 Radiologists},
  year      = {2019},
  month     = {mar},
  number    = {9},
  pages     = {916--922},
  volume    = {111},
  comment   = {DL surpassing HL performance on breast cancer detection},
  doi       = {10.1093/jnci/djy222},
  publisher = {Oxford University Press ({OUP})},
}

@Article{Hannun2019,
  author    = {Awni Y. Hannun and Pranav Rajpurkar and Masoumeh Haghpanahi and Geoffrey H. Tison and Codie Bourn and Mintu P. Turakhia and Andrew Y. Ng},
  journal   = {Nature Medicine},
  title     = {Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network},
  year      = {2019},
  month     = {jan},
  number    = {1},
  pages     = {65--69},
  volume    = {25},
  comment   = {DL surapssing HL performance on arrhytmia detection},
  doi       = {10.1038/s41591-018-0268-3},
  publisher = {Springer Science and Business Media {LLC}},
}

@Misc{Ronneberger2015,
  author    = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  year      = {2015},
  comment   = {U-Net},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1505.04597},
  file      = {:/home/kuntik/Documents/svp/papers/U-Net.pdf:PDF},
  groups    = {architectures},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  publisher = {arXiv},
}

@InProceedings{Baheti2020,
  author    = {Bhakti Baheti and Shubham Innani and Suhas Gajre and Sanjay Talbar},
  booktitle = {2020 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
  title     = {Eff-{UNet}: A Novel Architecture for Semantic Segmentation in Unstructured Environment},
  year      = {2020},
  month     = {jun},
  publisher = {{IEEE}},
  comment   = {EfficientNet Unet},
  doi       = {10.1109/cvprw50498.2020.00187},
  file      = {:/home/kuntik/Documents/svp/papers/EffUnet.pdf:PDF},
  groups    = {architectures},
}

@Misc{Lin2017,
  author    = {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár, Piotr},
  title     = {Focal Loss for Dense Object Detection},
  year      = {2017},
  comment   = {RetinaNet},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1708.02002},
  file      = {:/home/kuntik/Documents/svp/papers/RetinaNet.pdf:PDF},
  groups    = {architectures},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Creanga2015,
  author  = {Creanga, Adriana and Geha, Hassem and Sankar, Vidya and Teixeira, Fabricio and McMahan, Clyde and Noujeim, Marcel},
  journal = {Imaging science in dentistry},
  title   = {Accuracy of digital periapical radiography and cone-beam computed tomography in detecting external root resorption},
  year    = {2015},
  month   = sep,
  pages   = {153--8},
  volume  = {45},
  comment = {Periapical image},
  doi     = {10.5624/isd.2015.45.3.153},
  groups  = {images},
}

@Misc{Panoramatic2017,
  month    = sep,
  title    = {What is a {Panoramic} {X}-{Ray}},
  year     = {2017},
  comment  = {Panoramatic X-ray},
  groups   = {images},
  journal  = {Mint Hill Dentistry},
  language = {en-US},
  url      = {https://www.minthilldentistry.com/panoramic-x-ray},
  urldate  = {2022-05-11},
}

@Article{,
  groups = {images},
}

@Misc{CV_TasksImage,
  author       = {Fei-Fei Li & Justin Johnson, Serena Yeung},
  howpublished = {CS231n: Convo-lutional Neural Networks for Visual Recognition,Stanford University},
  month        = may,
  title        = {Detection and Segmentation},
  year         = {2017},
  comment      = {Computer vision tasks},
  groups       = {images},
  url          = {http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture11.pdf},
  urldate      = {2022-05-11},
}

@Misc{Haghanifar2020,
  author    = {Haghanifar, Arman and Majdabadi, Mahdiyar Molahasani and Ko, Seok-Bum},
  title     = {PaXNet: Dental Caries Detection in Panoramic X-ray using Ensemble Transfer Learning and Capsule Classifier},
  year      = {2020},
  comment   = {Panoramatic images, teeth detection, but caries as well},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  doi       = {10.48550/ARXIV.2012.13666},
  groups    = {Dental},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{Kumar2018,
  author    = {Kumar, Pratyush and Srivastava, Muktabh Mayank},
  title     = {Example Mining for Incremental Learning in Medical Imaging},
  year      = {2018},
  comment   = {Bitewing production software},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
  doi       = {10.48550/ARXIV.1807.08942},
  file      = {:/home/kuntik/Documents/svp/papers/srivastava_production.pdf:PDF},
  groups    = {Dental},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Zhang2019,
  author  = {Zhang, Xiangrong and Han, Xiao and Li, Chen and Tang, Xu and Zhou, Huiyu and Jiao, Licheng},
  journal = {Remote Sensing},
  title   = {Aerial Image Road Extraction Based on an Improved Generative Adversarial Network},
  year    = {2019},
  month   = apr,
  pages   = {930},
  volume  = {11},
  comment = {Unet vs FCNN},
  doi     = {10.3390/rs11080930},
}

@Article{AbdallaAslan2020,
  author    = {Ragda Abdalla-Aslan and Talia Yeshua and Daniel Kabla and Isaac Leichter and Chen Nadler},
  journal   = {Oral Surgery, Oral Medicine, Oral Pathology and Oral Radiology},
  title     = {An artificial intelligence system using machine-learning for automatic detection and classification of dental restorations in panoramic radiography},
  year      = {2020},
  month     = {nov},
  number    = {5},
  pages     = {593--602},
  volume    = {130},
  comment   = {Non-DL restoration segmentation},
  doi       = {10.1016/j.oooo.2020.05.012},
  file      = {:/home/kuntik/Documents/svp/papers/RestorationSegmentationNONDL.pdf:PDF},
  groups    = {Dental},
  publisher = {Elsevier {BV}},
}

@Article{Lee2021,
  author    = {Shinae Lee and Sang-il Oh and Junik Jo and Sumi Kang and Yooseok Shin and Jeong-won Park},
  journal   = {Scientific Reports},
  title     = {Deep learning for early dental caries detection in bitewing radiographs},
  year      = {2021},
  month     = {aug},
  number    = {1},
  volume    = {11},
  comment   = {Segmentation bitewing rich annotations},
  doi       = {10.1038/s41598-021-96368-7},
  file      = {:/home/kuntik/Documents/svp/papers/CariesDetectionSegRichAnnotation.pdf:PDF},
  groups    = {Dental},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Yeshua2019,
  author    = {Talia Yeshua and Ya{\textquotesingle}akov Mandelbaum and Ragda Abdalla-Aslan and Chen Nadler and Laureen Cohen and Levana Zemour and Daniel Kabla and Ori Gleisner and Isaac Leichter},
  journal   = {Issues in Informing Science and Information Technology},
  title     = {Automatic Detection and Classification of Dental Restorations in Panoramic Radiographs},
  year      = {2019},
  pages     = {221--234},
  volume    = {16},
  comment   = {Segmentation from panaramatic images - restorations},
  doi       = {10.28945/4306},
  groups    = {Dental},
  publisher = {Informing Science Institute},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:images\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:architectures\;0\;0\;0x8a8a8aff\;\;\;;
1 StaticGroup:metrics\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Dental\;0\;1\;0x8a8a8aff\;\;\;;
}
